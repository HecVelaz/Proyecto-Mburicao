{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d9f957-d099-4735-b42d-ab853ffdff09",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fb6e386-a898-43c9-9ba6-9057a34b224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b980020-35cb-4a9e-ac56-00261b4fc5ff",
   "metadata": {},
   "source": [
    "# 2. Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ac41621-3dff-4838-9d48-63b1dda87da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/home/nivelrios/documentos/Mburicao Project/data/external/sil_nivel_merged.csv')\n",
    "picos = pd.read_csv('/home/nivelrios/documentos/Mburicao Project/data/external/peak_nivel_detection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ff6cb-3614-4afe-85b7-344e1f9cb869",
   "metadata": {},
   "source": [
    "# 3. Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d828a67a-e918-4898-8b77-4272e8da9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['fecha'] = pd.to_datetime(merged['fecha'], errors='coerce')\n",
    "\n",
    "picos['inicio'] = pd.to_datetime(picos['inicio'], errors='coerce')\n",
    "picos['fin'] = pd.to_datetime(picos['fin'], errors='coerce')\n",
    "picos['max_global_fecha'] = pd.to_datetime(picos['max_global_fecha'], errors='coerce')\n",
    "picos['max_local_fecha'] = pd.to_datetime(picos['max_local_fecha'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68922313-e307-4bb1-8188-985a7a545e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fecha\" in merged.columns:\n",
    "    merged[\"fecha\"] = pd.to_datetime(merged[\"fecha\"], errors='coerce')\n",
    "    merged.set_index(\"fecha\", inplace=True)\n",
    "else:\n",
    "    merged.index = pd.to_datetime(merged.index, errors='coerce')\n",
    "picos[\"max_global_fecha\"] = pd.to_datetime(picos[\"max_global_fecha\"], errors='coerce')\n",
    "\n",
    "features_list = []\n",
    "\n",
    "for idx, row in picos.iterrows():\n",
    "    base_time = row[\"max_global_fecha\"]\n",
    "    global_peak = row[\"max_global\"]\n",
    "    all_dates_exist = True\n",
    "    for delay in range(0, 121, 10):\n",
    "        time_point = base_time - datetime.timedelta(minutes=delay)\n",
    "        if time_point not in merged.index:\n",
    "            all_dates_exist = False\n",
    "            break\n",
    "    if not all_dates_exist:\n",
    "        continue\n",
    "    feature_dict = {\n",
    "        \"fecha\": base_time,\n",
    "        \"global_peak\": global_peak\n",
    "    }\n",
    "    for delay in range(0, 81, 10):\n",
    "        col_name = f\"sil_{delay}\"\n",
    "        time_point = base_time - datetime.timedelta(minutes=delay)\n",
    "        sil_value = merged.loc[time_point, \"sil\"]\n",
    "        if isinstance(sil_value, pd.Series):\n",
    "            sil_value = sil_value.iloc[0]\n",
    "        feature_dict[col_name] = sil_value\n",
    "    for accum_delay in range(0, 71, 10):\n",
    "        col_accum = f\"sil_accumulated_{accum_delay}\"\n",
    "        total = 0\n",
    "        for d in range(accum_delay, 81, 10):\n",
    "            total += feature_dict[f\"sil_{d}\"]\n",
    "        feature_dict[col_accum] = round(total, 1)\n",
    "\n",
    "    features_list.append(feature_dict)\n",
    "data = pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b881f85-d290-45eb-a55b-f7a0410ac7eb",
   "metadata": {},
   "source": [
    "# 4. Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6817b910-2264-4c89-95af-d4972c279f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"/home/nivelrios/documentos/Mburicao Project/src/data\"\n",
    "os.makedirs(ruta, exist_ok=True)\n",
    "archivo = os.path.join(ruta, \"data_extraction.csv\")\n",
    "data.to_csv(archivo, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
